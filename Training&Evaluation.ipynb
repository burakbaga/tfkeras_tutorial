{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fdc212-fed9-4fe5-8b0a-3383167604a0",
   "metadata": {},
   "source": [
    "# Training & evaluation with the built-in methods\n",
    "## API genel bakış: İlk end-to-end örnek \n",
    "Bir modele data gönderiyorsak, numpy array yada tf.data objesi kullanmamız gerekiyor. Data küçükse numpy array yeterli olabilir. \n",
    "Mnist datası için bir model oluşturalım.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2916dbb4-8f55-42e4-90d2-e7f89d6f74e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e22594a-fa75-4a14-95fb-38d636f0a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b021b-aea2-4288-867d-57e9cb42b501",
   "metadata": {},
   "source": [
    "Genellikle end-to-end bir akış aşağıdakileri içermelidir. \n",
    "* Training\n",
    "* Validation (Training verisinden çıkarılmış)\n",
    "* Evaluation (Test verisinde)\n",
    "\n",
    "Bu örnek için mnist datasını kullanalım: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f9adce-6f4b-42a6-9f30-2ea1957ef7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1,784).astype(\"float32\")/255\n",
    "x_test = x_test.reshape(-1,784).astype(\"float32\")/255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# son 10000 data validation için ayrılıyor. \n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd80cd5f-98fa-49c8-a701-fd60ae66c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim için gerekli konfigurasyonları yapalım. \n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "             loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=[keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "802e31db-e24c-4e5f-b853-fa1fcd9078d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeli eğitim verisi üzerinde çalıştıralım\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 5s 4ms/step - loss: 0.3405 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.2220 - val_sparse_categorical_accuracy: 0.9342\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1624 - sparse_categorical_accuracy: 0.9520 - val_loss: 0.1748 - val_sparse_categorical_accuracy: 0.9488\n"
     ]
    }
   ],
   "source": [
    "# fit metodunu çağırarak model eğitimini başlatacağız. \n",
    "# Eğitimi datayı batchlere bölerek yapacağız. Batchler halinde tüm verisetinde gezerek belirtilen epoch kadar eğitim yapılacak. \n",
    "print(\"Modeli eğitim verisi üzerinde çalıştıralım\")\n",
    "history = model.fit(x_train,y_train,batch_size=64,epochs=2,validation_data = (x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5770520e-333e-4ab7-80b3-c4e504bf4ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3405407667160034, 0.16236719489097595],\n",
       " 'sparse_categorical_accuracy': [0.9024199843406677, 0.9520400166511536],\n",
       " 'val_loss': [0.22197943925857544, 0.17477765679359436],\n",
       " 'val_sparse_categorical_accuracy': [0.9341999888420105, 0.9488000273704529]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit metodundan bir history objesi döndürdük. \n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36b21f4-9be9-4101-b1e2-80915cef69e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test datası ile evaluate etme: \n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1782 - sparse_categorical_accuracy: 0.9473\n",
      "Test loss ve test acc değerleri :  [0.17820633947849274, 0.9473000168800354]\n",
      "Prediction\n",
      "[[1.9401762e-06 2.4910689e-08 1.2575711e-04 2.6023012e-04 2.7782872e-09\n",
      "  5.7926991e-06 1.5849018e-10 9.9960345e-01 7.9646156e-07 1.9024847e-06]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate ile modeli değerlendirelim \n",
    "print(\"Test datası ile evaluate etme: \")\n",
    "results = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"Test loss ve test acc değerleri : \",results)\n",
    "\n",
    "# Prediction için : \n",
    "print(\"Prediction\")\n",
    "prediction = model.predict(x_test[0].reshape(1,-1))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225b753-04d1-42b1-af04-96705f00c242",
   "metadata": {},
   "source": [
    "## Workflodaki adımlara ayrıntılı olarak bakalım\n",
    "### Compile Metodu, loss-metrics-optimizer\n",
    "Model eğitimini başlatmak için loss, optimizer ve başarıyı ölçümleyecek metriklere ihtiyaç vardır. Bu parametreleri compile metoduna argument olarak göndeririz.   \n",
    "Metric parametresi liste şeklinde bir modelin istenilen sayıda metriği olabilir.  \n",
    "Eğer modelin birden fazla outputu varsa, her output için farklı loss ve metrikler belirleyebiliriz. Her outputun total loss a ne kadar etki edeceğini de ayarlayabiliriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d799a496-f97e-42cf-9294-9ee7f441287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "             loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "# ikiside aynı şekilde çalışır \n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87ae02d-a8a9-4101-a711-e978ef6899bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAHA SONRA KULLANMAK İÇİN MODELİ VE COMPILE İŞLEMİ İÇİN FONKSİYONLAR OLUŞTURALIM\n",
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47f233-a0a5-4b5c-a387-67a47fcf5a9c",
   "metadata": {},
   "source": [
    "### Bir çok built-in optimizers, loss, metrik vardır. \n",
    "Genellikle kendi loss,metrik, optimizer larını oluşturmamıza gerek kalmaz. Bunların hepsi Keras API de vardır. \n",
    "Optimizers: \n",
    "* SGD()\n",
    "* RMSporp()\n",
    "* Adam()\n",
    "* etc\n",
    "\n",
    "Losses: \n",
    "* MeanSquaredError()\n",
    "* KLDivergence()\n",
    "* CosineSimilarity()\n",
    "* etc.\n",
    "\n",
    "Metrics: \n",
    "* AUC()\n",
    "* Precision()\n",
    "* Recall()\n",
    "* etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d886b11-6df6-43e9-b6a3-0c5a01b4365c",
   "metadata": {},
   "source": [
    "## Custom Loss \n",
    "Eğer custom loss oluşturmak istiyorsak kerasta 2 yöntem vardır.  \n",
    "y_true ve y_pred değerlerini alan bir fonksiyon tanımlayabiliriz. Aşağıdaki örnekte mean squared error hesaplayan bir fonksiyon bulunuyor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebd383bf-322e-4b5d-a5ac-1e5a48dff39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd1b241be0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_mean_squared_error(y_true,y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred)) \n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(),loss=custom_mean_squared_error)\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train,depth=10)\n",
    "model.fit(x_train,y_train_one_hot,batch_size=64,epochs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463ee29-8940-488a-8272-afdea8512e50",
   "metadata": {},
   "source": [
    "Diğer yöntemde ise tf.keras.losses.Loss classını implemente edebiliriz. \n",
    "* __init__(self) : call sırasında çağrılacak parametreler için gereklidir\n",
    "* call(self,y_true,y_pred): target ve predictionları kullanarak loss hesapla\n",
    "\n",
    "Örneğin, mean squared error kullanmak istiyoruz ama aynı zamanda bir regularization değeri ile modelin 0.5 ten yukarı tahminlerinin etksinin artırmak istiyoruz. Bu sayede overfittingin de önüne geçmiş oluruz. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74bd862e-4009-4d89-8021-d944282c4416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd2119dc50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6918607f-74c9-4961-974d-da224d46d8fd",
   "metadata": {},
   "source": [
    "## Custom Metrics\n",
    "Eğer Keras API de bulunan metrikler dışında bir metrik oluşturmak istersek, kolayca custom metrikler oluşturabiliriz. Bunu için tf.keras.metrics.Metric sınıfından bir sınıf extend ederek aşağıdaki 4 metodu uygulamanız gerekiyor. \n",
    "* __init__(self) : metrik için gerekli olan değişkenleri tanımlamak için \n",
    "* update_state(self,y_true,y_pred,sample_weight=None): y_true ve y_pred'i kullanarak değişkenleri update eder\n",
    "* result(self) : Değişkenleri kullanarak son hesaplamayı yapar\n",
    "* reset_states(self): metrik içerisindeki değerleri tekrar başlatır. \n",
    "\n",
    "State_update ve result hesapları ayrı yapılır. Sonuç hesabı belli maliyetli olabilir bu sebeple periyodik olarak yapılmalı.  \n",
    "\n",
    "Aşağıdaki örnekte CategoricalTruePositives metriğini oluşturalım. Bu metrik ile kaç tane örnek doğru sınıflandırıldığını hesaplıyoruz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "985d06e5-bf49-4b7e-aec1-ced2280a48fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 4s 4ms/step - loss: 0.3398 - categorical_true_positives: 45215.0000\n",
      "Epoch 2/3\n",
      " 42/782 [>.............................] - ETA: 2s - loss: 0.1638 - categorical_true_positives: 2561.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bagat\\anaconda3\\envs\\tod\\lib\\site-packages\\keras\\metrics.py:257: UserWarning: Metric CategoricalTruePositives implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  'consistency.' % (self.__class__.__name__,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1617 - categorical_true_positives: 47574.0000\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.1155 - categorical_true_positives: 48259.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd243ea978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f50eaf-8bf2-4f54-9ffd-6bf5f966b20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65146d3-dd0f-4936-99d4-91f75b92fdd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4026af54-aef4-4c2e-af8a-09b082c02e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124bf2c-8f4a-4c24-b64b-242e4e90cbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a927b-5d72-4c40-b156-377fdff3d07a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4126d-a027-4915-bd1a-29c463f0707e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tod",
   "language": "python",
   "name": "tod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
